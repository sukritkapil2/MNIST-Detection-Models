{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEL TOPICS ASSIGNMENT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDWfT4sS7Cyz"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "\n",
        "size_img = 28\n",
        "threshold_color = 100 / 255\n",
        "\n",
        "\n",
        "def int2float_grey(x):\n",
        "    x = x / 255\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_dataset():\n",
        "    # Any results you write to the current directory are saved as output.\n",
        "    with open(\"./Dataset/mnist_train.csv\") as file:\n",
        "        data_train = pd.read_csv(file)\n",
        "\n",
        "        # y_train has the label, x_train has the image data\n",
        "        y_train = np.array(data_train.iloc[:, 0])\n",
        "        x_train = np.array(data_train.iloc[:, 1:])\n",
        "\n",
        "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
        "                                                          train_size=0.8, test_size=0.2,\n",
        "                                                          random_state=1)\n",
        "\n",
        "    with open(\"./Dataset/mnist_test.csv\") as file:\n",
        "        data_test = pd.read_csv(file)\n",
        "\n",
        "        # y_test has the label, x_test has the image data\n",
        "        y_test = np.array(data_test.iloc[:, 0])\n",
        "        x_test = np.array(data_test.iloc[:, 1:])\n",
        "\n",
        "        n_features_train = x_train.shape[1]\n",
        "        n_samples_train = x_train.shape[0]\n",
        "        n_samples_test = x_test.shape[0]\n",
        "\n",
        "        x_train = int2float_grey(x_train)\n",
        "        x_test = int2float_grey(x_test)\n",
        "\n",
        "        x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "        x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
        "        x_val = np.reshape(x_val, (-1, 28, 28, 1))\n",
        "\n",
        "        y_train = to_categorical(y_train)\n",
        "        y_test = to_categorical(y_test)\n",
        "        y_val = to_categorical(y_val)\n",
        "\n",
        "        print(f\"Features : {n_features_train}\")\n",
        "        print(f\"Number of training samples : {n_samples_train}\")\n",
        "        print(f\"Number of Testing Samples : {n_samples_test}\")\n",
        "        print(f\"x_train shape : {x_train.shape}\")\n",
        "        print(f\"y_train shape : {y_train.shape}\")\n",
        "        print(f\"x_test shape : {x_test.shape}\")\n",
        "        print(f\"y_test shape : {y_test.shape}\")\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, x_val, y_val\n",
        "\n",
        "def colab_fetch_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
        "                                                          train_size=0.8, test_size=0.2,\n",
        "                                                          random_state=1)\n",
        "    \n",
        "    n_features_train = x_train.shape[1]\n",
        "    n_samples_train = x_train.shape[0]\n",
        "    n_samples_test = x_test.shape[0]\n",
        "\n",
        "    x_train = int2float_grey(x_train)\n",
        "    x_test = int2float_grey(x_test)\n",
        "\n",
        "    x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "    x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
        "    x_val = np.reshape(x_val, (-1, 28, 28, 1))\n",
        "\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_val = to_categorical(y_val)\n",
        "\n",
        "    print(f\"Features : {n_features_train}\")\n",
        "    print(f\"Number of training samples : {n_samples_train}\")\n",
        "    print(f\"Number of Testing Samples : {n_samples_test}\")\n",
        "    print(f\"x_train shape : {x_train.shape}\")\n",
        "    print(f\"y_train shape : {y_train.shape}\")\n",
        "    print(f\"x_test shape : {x_test.shape}\")\n",
        "    print(f\"y_test shape : {y_test.shape}\")\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, x_val, y_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LISLm3R7F88"
      },
      "source": [
        "# Import Keras and Tensorflow\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from tensorflow.python.keras.layers import Conv2D, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Import Training, Testing and Validation\n",
        "x_train, y_train, x_test, y_test, x_val, y_val = colab_fetch_mnist()\n",
        "\n",
        "\n",
        "# Define different model architectures\n",
        "def model1():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(20, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=(28, 28, 1)))\n",
        "    # model.add(BatchNormalization())\n",
        "    model.add(Conv2D(20, kernel_size=(3, 3), activation='relu', strides=2))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def cnn_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # two convolution layers, with one max-pooling and dropout\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # two convolution layers, with one max-pooling and dropout\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # two convolution layers, with one max-pooling and dropout\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # final fully connected layers, for which flattening is needed initially\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def compile_and_train_model(model, number):\n",
        "    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    datagen = ImageDataGenerator(zoom_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 rotation_range=10)\n",
        "\n",
        "    hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
        "                               steps_per_epoch=500,\n",
        "                               epochs=30,\n",
        "                               verbose=2,\n",
        "                               validation_data=(x_val, y_val),\n",
        "                               callbacks=[annealer,\n",
        "                                          ModelCheckpoint(f'model{number}.h5', save_best_only=True)])\n",
        "\n",
        "    final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "    print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))\n",
        "\n",
        "    plt.plot(hist.history['loss'], color='b')\n",
        "    plt.plot(hist.history['val_loss'], color='r')\n",
        "    plt.show()\n",
        "    plt.plot(hist.history['accuracy'], color='b')\n",
        "    plt.plot(hist.history['val_accuracy'], color='r')\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "model = cnn_model()\n",
        "compile_and_train_model(model, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30wyhj9jCyAi"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('model1.h5')\n",
        "\n",
        "x_train, y_train, x_test, y_test, x_val, y_val = colab_fetch_mnist()\n",
        "\n",
        "print(\"Making Predictions\")\n",
        "\n",
        "# y_pred = model.predict_classes(x_test)\n",
        "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
        "acc = np.sum(y_pred == y_test) / np.size(y_pred)\n",
        "print(\"[RESULT] TEST ACCURACY = {}\".format(acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}